#!/usr/bin/env python3
"""Test Bark TTS installation"""

import torch
from transformers import AutoProcessor, BarkModel

print("ðŸŽµ Testing Bark TTS Installation...")
print(f"âœ“ PyTorch version: {torch.__version__}")
print(f"âœ“ CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    try:
        print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
    except Exception:
        print("âœ“ GPU available (name could not be retrieved)")

print("\nðŸ“¥ Loading Bark model (this will download ~2-3GB on first run)...")
processor = AutoProcessor.from_pretrained("suno/bark")
model = BarkModel.from_pretrained(
    "suno/bark",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
)

if torch.cuda.is_available():
    model = model.to("cuda")
    print("âœ“ Model loaded on GPU")
else:
    print("âš  Model loaded on CPU (will be slower)")

print("\nðŸŽ¤ Generating test audio...")
inputs = processor("â™ª Yo-ho-ho and a bottle of rum! â™ª", voice_preset="v2/en_speaker_6")

if torch.cuda.is_available():
    inputs = {k: v.to("cuda") for k, v in inputs.items()}

with torch.no_grad():
    audio = model.generate(**inputs)

print("âœ… Success! Bark is working correctly.")
print("\nYou can now run the full application.")

